{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:44.431606400Z",
     "start_time": "2023-09-04T15:05:26.417418200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras -q\n",
    "%pip install keras_cv -q\n",
    "%pip install keras_core -q\n",
    "\n",
    "%pip install tensorflow -q\n",
    "%pip install numpy -q\n",
    "\n",
    "%pip install wandb -q\n",
    "%pip install ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:55.014368600Z",
     "start_time": "2023-09-04T15:05:44.431606400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 17:05:45.669881: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-04 17:05:45.969455: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-04 17:05:45.971625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-04 17:05:47.694002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.ragged import constant\n",
    "\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box, visualization\n",
    "from random import SystemRandom\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import wandb\n",
    "from wandb import init\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:55.014368600Z",
     "start_time": "2023-09-04T15:05:55.013343400Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch: int = 15\n",
    "batch_size: int = 4\n",
    "\n",
    "learning_rate: float = 0.002\n",
    "\n",
    "target_size_width: int = 640\n",
    "target_size_height: int = 640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:55.017344800Z",
     "start_time": "2023-09-04T15:05:55.014368600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_model: bool = False\n",
    "\n",
    "split_at: float = 0.15\n",
    "\n",
    "global_clip_at: float = 10.0\n",
    "boundary_format: str = 'xyxy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:55.017344800Z",
     "start_time": "2023-09-04T15:05:55.014368600Z"
    }
   },
   "outputs": [],
   "source": [
    "labels: list = [\n",
    "    'Dog',\n",
    "    'Dog tag',\n",
    "    'Collar'\n",
    "]\n",
    "\n",
    "labels_mapped: dict = dict(\n",
    "    zip(\n",
    "        range(len(labels)), \n",
    "        labels\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_paths: dict = dict(\n",
    "    {\n",
    "        'images': '/home/jupyter/datasets/Tracking Madsen/Images',\n",
    "        'annotations': '/home/jupyter/datasets/Tracking Madsen/Annotations'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:55.018985400Z",
     "start_time": "2023-09-04T15:05:55.015346200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configuration: dict = {\n",
    "    'target': {\n",
    "        'width': target_size_width,\n",
    "        'height': target_size_height\n",
    "    },\n",
    "    'model': {\n",
    "        'epochs': epoch,\n",
    "        'batch size': batch_size,\n",
    "        'boundary format': boundary_format,\n",
    "        'name': 'yolo'\n",
    "    },\n",
    "    'dataset':\n",
    "    {\n",
    "        'paths': dataset_paths,\n",
    "        'labels': labels_mapped,\n",
    "        'split': split_at\n",
    "    },\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:05:58.361060600Z",
     "start_time": "2023-09-04T15:05:55.015346200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdesignermadsen\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc2b3ebad8f4717bca8ff5fdecd6b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667007303334079, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20230904_170557-fa31rhkl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/designermadsen/Mj%C3%B8lner/runs/fa31rhkl' target=\"_blank\">gentle-dew-7</a></strong> to <a href='https://wandb.ai/designermadsen/Mj%C3%B8lner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/designermadsen/Mj%C3%B8lner' target=\"_blank\">https://wandb.ai/designermadsen/Mj%C3%B8lner</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/designermadsen/Mj%C3%B8lner/runs/fa31rhkl' target=\"_blank\">https://wandb.ai/designermadsen/Mj%C3%B8lner/runs/fa31rhkl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/designermadsen/Mj%C3%B8lner/runs/fa31rhkl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1c8494ee00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init(\n",
    "    project='Mjølner', \n",
    "    entity='designermadsen',\n",
    "    save_code=True,\n",
    "    config = configuration,\n",
    "    sync_tensorboard = True,\n",
    "    job_type='Training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:06:06.380661100Z",
     "start_time": "2023-09-04T15:05:58.374857400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b590823238e4c69b54ab6bd05c541e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xml_files = sorted(\n",
    "    [\n",
    "        join(dataset_paths['annotations'], file_name)\n",
    "        for file_name in listdir(dataset_paths['annotations'])\n",
    "        if file_name.lower().endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "size_of_annotations = len(xml_files)\n",
    "\n",
    "image_files = sorted(\n",
    "    [\n",
    "        join(dataset_paths['images'], file_name)\n",
    "        for file_name in listdir(dataset_paths['images'])\n",
    "        if file_name.lower().endswith(\".jpg\") or file_name.lower().endswith(\".jpeg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def parse_xml(\n",
    "    xml_file\n",
    "):\n",
    "    global dataset_paths, labels_mapped\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = join(dataset_paths['images'], image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "\n",
    "    for object in root.iter('object'):\n",
    "        cls = object.find(\"name\").text\n",
    "        classes.append(cls)\n",
    "\n",
    "        bounderies = object.find(\"bndbox\")\n",
    "        xmin: float = float(bounderies.find('xmin').text)\n",
    "        ymin: float = float(bounderies.find('ymin').text)\n",
    "\n",
    "        xmax: float = float(bounderies.find('xmax').text)\n",
    "        ymax: float = float(bounderies.find('ymax').text)\n",
    "\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "    \n",
    "    label_ids: list = [\n",
    "        list(labels_mapped.keys())[list(labels_mapped.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    \n",
    "    return image_path, boxes, label_ids\n",
    "\n",
    "image_paths = []\n",
    "boundaries = []\n",
    "classes = []\n",
    "\n",
    "for file in tqdm(\n",
    "    xml_files\n",
    "):\n",
    "    image_path, boxes, label_ids = parse_xml(\n",
    "        file\n",
    "    )\n",
    "    \n",
    "    image_paths.append(\n",
    "        image_path\n",
    "    )\n",
    "    \n",
    "    boundaries.append(\n",
    "        boxes\n",
    "    )\n",
    "    \n",
    "    classes.append(\n",
    "        label_ids\n",
    "    )\n",
    "\n",
    "image_paths = constant(image_paths)\n",
    "classes = constant(classes)\n",
    "boundaries = constant(boundaries)\n",
    "\n",
    "dataset = tensorflow.data.Dataset.from_tensor_slices((\n",
    "    image_paths,\n",
    "    classes,\n",
    "    boundaries\n",
    "))\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = tensorflow.io.read_file(image_path)\n",
    "    image = tensorflow.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "def load_dataset(\n",
    "    image_path, \n",
    "    classes, \n",
    "    bounderies\n",
    "):\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tensorflow.cast(\n",
    "            classes, \n",
    "            dtype=tensorflow.float32\n",
    "        ),\n",
    "        \"boxes\": bounderies\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"images\": tensorflow.cast(\n",
    "            image, \n",
    "            dtype=tensorflow.float32\n",
    "        ), \n",
    "        \"bounding_boxes\": bounding_boxes\n",
    "    }\n",
    "\n",
    "resize = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(target_size_height, target_size_width),\n",
    "            scale_factor=(0.5, 2.0),\n",
    "            bounding_box_format=boundary_format\n",
    "        ),\n",
    "        \n",
    "        keras_cv.layers.AutoContrast([0, 1])\n",
    "    ]\n",
    ")\n",
    "\n",
    "number_of_validation: int = int(size_of_annotations * split_at)\n",
    "\n",
    "validation_data = dataset.take(\n",
    "    number_of_validation\n",
    ")\n",
    "\n",
    "training_data = dataset.skip(\n",
    "    number_of_validation\n",
    ")\n",
    "\n",
    "training_data = training_data.map(\n",
    "    load_dataset, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "training_data = training_data.shuffle(batch_size * 4)\n",
    "\n",
    "training_data = training_data.ragged_batch(\n",
    "    batch_size, \n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "training_data = training_data.map(\n",
    "    resize, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "\n",
    "validation_data = validation_data.map(\n",
    "    load_dataset, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "validation_data = validation_data.shuffle(batch_size * 4)\n",
    "\n",
    "validation_data = validation_data.ragged_batch(\n",
    "    batch_size, \n",
    "    drop_remainder=True\n",
    ")\n",
    "\n",
    "validation_data = validation_data.map(\n",
    "    resize, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "def visualise_dataset(\n",
    "        dataset_as_input, \n",
    "        value_range, \n",
    "        rows, \n",
    "        cols, \n",
    "        bounding_box_format\n",
    "):\n",
    "    global labels_mapped\n",
    "    dataset_as_input = next(iter(dataset_as_input.take(1)))\n",
    "    images, bounding_boxes = dataset_as_input[\"images\"], dataset_as_input[\"bounding_boxes\"]\n",
    "    \n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.5,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=labels_mapped\n",
    "    )\n",
    "\n",
    "visualise_dataset_before_run: bool = False\n",
    "\n",
    "if visualise_dataset_before_run:\n",
    "    visualise_dataset(\n",
    "        training_data, \n",
    "        bounding_box_format=boundary_format, \n",
    "        value_range=(0, 255), \n",
    "        rows=2, \n",
    "        cols=2\n",
    "    )\n",
    "\n",
    "    visualise_dataset(\n",
    "        validation_data, \n",
    "        bounding_box_format=boundary_format, \n",
    "        value_range=(0, 255), \n",
    "        rows=2, \n",
    "        cols=2\n",
    "    )\n",
    "\n",
    "def dict_to_tuple(\n",
    "    inputs: dict\n",
    ") -> tuple:\n",
    "    return inputs['images'], inputs['bounding_boxes']\n",
    "\n",
    "training_data = training_data.map(\n",
    "    dict_to_tuple, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "training_data = training_data.prefetch(\n",
    "    tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "validation_data = validation_data.map(\n",
    "    dict_to_tuple, \n",
    "    num_parallel_calls=tensorflow.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "validation_data = validation_data.prefetch(\n",
    "    tensorflow.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:06:10.988827200Z",
     "start_time": "2023-09-04T15:06:06.380661100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    'yolo_v8_l_backbone'\n",
    ")\n",
    "\n",
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(labels_mapped),\n",
    "    bounding_box_format=boundary_format,\n",
    "    backbone=backbone,\n",
    "    fpn_depth=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:06:10.989830600Z",
     "start_time": "2023-09-04T15:06:10.988827200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tensorflow.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate,\n",
    "    global_clipnorm=global_clip_at,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer, \n",
    "    classification_loss=\"binary_crossentropy\", \n",
    "    box_loss=\"ciou\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:06:10.990840700Z",
     "start_time": "2023-09-04T15:06:10.988827200Z"
    }
   },
   "outputs": [],
   "source": [
    "if graph_model:\n",
    "    plot_model(\n",
    "        yolo, \n",
    "        to_file='D:/Model/yolo.png', \n",
    "        show_shapes=True, \n",
    "        show_trainable=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-04T15:06:10.990840700Z",
     "start_time": "2023-09-04T15:06:10.988827200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histories: list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-04T15:06:10.989830600Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "424/424 [==============================] - ETA: 0s - loss: 33.5694 - box_loss: 2.3042 - class_loss: 31.2652"
     ]
    }
   ],
   "source": [
    "history = yolo.fit(\n",
    "    training_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=epoch,\n",
    "    use_multiprocessing=True,\n",
    "    \n",
    "    workers=8,\n",
    "    \n",
    "    callbacks=[\n",
    "        WandbMetricsLogger()\n",
    "    ]\n",
    ")\n",
    "\n",
    "histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_locations: str = '/home/jupyter/models/'\n",
    "if not isdir(model_locations):\n",
    "    mkdir(model_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_at: str = join(\n",
    "    model_locations, \n",
    "    'yolo'\n",
    ")\n",
    "\n",
    "save_model_when_done: bool = True\n",
    "\n",
    "save_to_wandb: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not isdir(save_model_at):\n",
    "    mkdir(save_model_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/tmp/model)... Done. 1.1s\n"
     ]
    }
   ],
   "source": [
    "if save_model_when_done:\n",
    "    yolo.save(\n",
    "        filepath=save_model_at, \n",
    "        save_format='keras',\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "if save_to_wandb and save_model_when_done:\n",
    "    artifact = wandb.Artifact(\n",
    "        name='mjoelner_vision_model', \n",
    "        type='model-keras'\n",
    "    )\n",
    "\n",
    "    artifact.add_dir(\n",
    "        local_path=save_model_at\n",
    "    )\n",
    "\n",
    "    wandb.log_artifact(\n",
    "        artifact\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/box_loss</td><td>▃▇█▁▁</td></tr><tr><td>epoch/class_loss</td><td>█▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▁▁▁▁</td></tr><tr><td>epoch/val_box_loss</td><td>█▆▆▁▁</td></tr><tr><td>epoch/val_class_loss</td><td>▆█▅▁▂</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/box_loss</td><td>2.30197</td></tr><tr><td>epoch/class_loss</td><td>0.78561</td></tr><tr><td>epoch/epoch</td><td>4</td></tr><tr><td>epoch/learning_rate</td><td>0.002</td></tr><tr><td>epoch/loss</td><td>3.08759</td></tr><tr><td>epoch/val_box_loss</td><td>1.79611</td></tr><tr><td>epoch/val_class_loss</td><td>0.92285</td></tr><tr><td>epoch/val_loss</td><td>2.71895</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-wood-20</strong> at: <a href='https://wandb.ai/designermadsen/YOLO/runs/b4ssq0w0' target=\"_blank\">https://wandb.ai/designermadsen/YOLO/runs/b4ssq0w0</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230903_134535-b4ssq0w0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
